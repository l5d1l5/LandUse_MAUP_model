{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import os\n",
    "import glob\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGRESJA LOGISTYCZNA\n",
    "def regresja(df, nazwa_modeli):\n",
    "    # usuwamy ownership bo bylo mieszajace\n",
    "    X  = df.drop(['las01', 'owner', 'Unnamed: 0'], axis=1) \n",
    "    Y = df.las01\n",
    "\n",
    "    # splasczenie zeminnej zaleznej bo musi byc splaszczona\n",
    "    y = np.ravel(Y)\n",
    "    \n",
    "    # podzial na test i train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "    \n",
    "    # podzial na test i train\n",
    "    log_model = LogisticRegression()\n",
    "    log_model.fit(X_train,y_train)\n",
    "    r2 = log_model.score(X,Y)\n",
    "    r2_test = log_model.score(X_test,y_test)\n",
    "    print(r2, r2_test)\n",
    "    \n",
    "    # Predict the labels of the test set: y_pred\n",
    "    y_pred = log_model.predict(X_test)\n",
    "    y_pred_prob = log_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Compute and print AUC score\n",
    "    auc_kurwa = roc_auc_score(y_test, y_pred_prob)\n",
    "    print(\"AUC: {}\".format(auc_kurwa), nazwa_modeli)\n",
    "    \n",
    "    # Generate ROC curve values: fpr, tpr, thresholds\n",
    "     #fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    # plt.plot([0, 1], [0, 1], 'k--')\n",
    "    # plt.plot(fpr, tpr)\n",
    "    # plt.xlabel('False Positive Rate')\n",
    "    # plt.ylabel('True Positive Rate')\n",
    "    # plt.title('ROC Curve')\n",
    "    # plt.show()\n",
    "\n",
    "    # Compute and print the confusion matrix and classification report\n",
    "    #print(confusion_matrix(y_test, y_pred))\n",
    "    #print(classification_report(y_test, y_pred))\n",
    "    #print(\"r2\", r2)\n",
    "    \n",
    "    # standardowy output regresji\n",
    "    coef_df = DataFrame(zip(X.columns, np.transpose(log_model.coef_)))\n",
    "    return(coef_df, r2, auc_kurwa, nazwa_modeli, r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def czyszczenie(df, cols_to_norm):\n",
    "    df2 = df.replace(-9999, np.NaN)\n",
    "    df3 = df2.dropna()\n",
    "     \n",
    "    ##normalizacja - nie jest w stanie zrobic normalizacji\n",
    "    df3[cols_to_norm] = df3[cols_to_norm].apply(lambda x: np.log(x))\n",
    "     \n",
    "    #standaryzacja, zeby zmienne byly porownywalne miedzy soba\n",
    "    df3[cols_to_norm] = df3[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "    return(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      
    }
   ],
   "source": [
    "lista_path = [r'c:\\doktorat\\czemp6\\kondracki_mezo',\n",
    "            r'c:\\doktorat\\czemp6\\kondracki_mezo_makro',\n",
    "            r'c:\\doktorat\\czemp6\\powiaty',\n",
    "            r'c:\\doktorat\\czemp6\\kwadraty_losowe',\n",
    "            r'c:\\doktorat\\czemp6\\kwadraty_10km']\n",
    "\n",
    "#lista_path = [r'c:\\doktorat\\czemp5\\konglomeraty_250\\kwadraty_losowe_25km']\n",
    "\n",
    "lista_nazw = ['geo_roznorodne', 'geo_jednorodne', 'powiaty', 'kwadraty_losowe', 'kwadraty_10km']\n",
    "cols_to_norm = ['dist_rds', 'farm','nach', 'pop_dens', 'prec',  'temp', 'tourism', 'tpi']\n",
    "\n",
    "#lista_nazw = ['kwadraty_25km_los']\n",
    "\n",
    "new_df = pd.DataFrame(columns = ['model', 'r2', 'r2_test', 'auc_kurwa', 'dist_rds', 'farm','nach', 'pop_dens',\n",
    "                                     'prec',  'temp', 'tourism', 'tpi', 'regiony'])\n",
    "indeks = 0\n",
    "for path in lista_path:\n",
    "    nazwa_modeli = lista_nazw[indeks]\n",
    "    indeks = indeks + 1\n",
    "    extension = 'csv'\n",
    "    os.chdir(path)\n",
    "    result = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "    for i in result:\n",
    "        try:\n",
    "            # dodac warunek, zeby model byl wiekszy, niz..\n",
    "            nazwa_modelu = str(i[:-4])\n",
    "            df = pd.read_csv(i)\n",
    "            \n",
    "            df_przeczyszczony = czyszczenie(df, cols_to_norm)\n",
    "            liczenie_regresji = regresja(df_przeczyszczony, nazwa_modeli)\n",
    "            df_coef = liczenie_regresji[0]\n",
    "            r2_wynik = liczenie_regresji[1]\n",
    "            auc_kurwa = liczenie_regresji[2]\n",
    "            r2_wynik_test = liczenie_regresji[4]\n",
    "            lista=[nazwa_modelu]\n",
    "            \n",
    "            for j in df_coef.itertuples():\n",
    "                lista.append(float(j[2]))\n",
    "\n",
    "            new_df = new_df.append({'model':lista[0], 'r2': r2_wynik,  'r2_test': r2_wynik_test, 'auc_kurwa': auc_kurwa,  'dist_rds':lista[1],'farm' :lista[2],'nach':lista[3],\n",
    "                                     'pop_dens':lista[4], 'prec':lista[5],  'temp':lista[6],\n",
    "                                     'tourism':lista[7], 'tpi':lista[8], 'regiony': nazwa_modeli}, ignore_index=True)\n",
    "        except:\n",
    "            print(\"das\")\n",
    "            \n",
    "path = r'c:\\doktorat\\czemp6\\regresje_zbiorcze'\n",
    "wyniki_regresji = os.path.join(path, \"wyniki_ROC_stand.csv\")\n",
    "new_df.to_csv(wyniki_regresji)\n",
    "new_df.head(4)\n",
    "new_df['r2'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"kondracki\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c0fe083ced23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtabelka\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'regiony'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auc_kurwa'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtabela_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtabelka\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtabela_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'regiony2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtabela_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtabela_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'regiony2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtabela_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'regiony2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\marci\\Anaconda2\\lib\\site-packages\\pandas\\core\\tools\\numeric.pyc\u001b[0m in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mcoerce_numeric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             values = lib.maybe_convert_numeric(values, set(),\n\u001b[1;32m--> 133\u001b[1;33m                                                coerce_numeric=coerce_numeric)\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"kondracki\" at position 0"
     ]
    }
   ],
   "source": [
    "\n",
    "# df1, df2\n",
    "# dodac pole - regiony + model\n",
    "# polaczyc, zapisac\n",
    "import pandas as pd\n",
    "import os\n",
    "df2 = pd.read_csv(r'c:\\doktorat\\czemp6\\regresje_zbiorcze\\konglomeraty_parametry_zbiorcze_v5.csv')\n",
    "new_df['lacznik'] = new_df['regiony'].astype(str) + new_df['model'].astype(str)\n",
    "df2['lacznik'] =df2['regiony'].astype(str) + df2['model'].astype(str)\n",
    "df_merged = pd.merge(new_df, df2, on=\"lacznik\", how = \"left\")\n",
    "\n",
    "path = r'c:\\doktorat\\czemp6\\regresje_zbiorcze'\n",
    "modele_parametry = os.path.join(path, \"modele_zbiorcze_wyniki_stand_param_roc_v6.csv\")\n",
    "\n",
    "df_merged.to_csv(modele_parametry)\n",
    "df_merged.head()\n",
    "\n",
    "tabelka = new_df.groupby('regiony')['auc_kurwa'].mean()\n",
    "tabela_df = pd.DataFrame(tabelka)\n",
    "tabela_df['regiony2'] = pd.to_numeric(tabela_df.index)\n",
    "tabela_df.sort_values('regiony2', inplace=True)\n",
    "_ = tabela_df.plot('regiony2', 'r2')\n",
    "_ = plt.xlabel('wielkosc mau')\n",
    "_= plt.ylabel('auc_kurwa')\n",
    "tabela_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regiony</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>0.795063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>0.825757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15900</th>\n",
       "      <td>0.790430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20800</th>\n",
       "      <td>0.789409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>0.812680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>0.801977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800</th>\n",
       "      <td>0.814260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               r2\n",
       "regiony          \n",
       "10400    0.795063\n",
       "1300     0.825757\n",
       "15900    0.790430\n",
       "20800    0.789409\n",
       "2600     0.812680\n",
       "5200     0.801977\n",
       "7800     0.814260"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
